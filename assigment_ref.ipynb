{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e536cb57-cfe8-4e98-8436-a54cb00dab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f56f522-612c-45d5-bad7-7779165564c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Text\n",
      "0     the rock is destined to be the 21st century's ...\n",
      "1     the gorgeously elaborate continuation of \" the...\n",
      "2                      effective but too-tepid biopic\\n\n",
      "3     if you sometimes like to go to the movies to h...\n",
      "4     emerges as something rare , an issue movie tha...\n",
      "...                                                 ...\n",
      "5326  both exuberantly romantic and serenely melanch...\n",
      "5327  mazel tov to a film about a family's joyous li...\n",
      "5328  standing in the shadows of motown is the best ...\n",
      "5329  it's nice to see piscopo again after all these...\n",
      "5330  provides a porthole into that noble , tremblin...\n",
      "\n",
      "[5331 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Open the file and read the lines into a list\n",
    "with open('positive.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "pos_df = pd.DataFrame(lines, columns=['Text'])\n",
    "\n",
    "print(pos_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19bdf2d8-1549-458a-9b89-beab5f774979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Text\n",
      "0                   simplistic , silly and tedious . \\n\n",
      "1     it's so laddish and juvenile , only teenage bo...\n",
      "2     exploitative and largely devoid of the depth o...\n",
      "3     [garbus] discards the potential for pathologic...\n",
      "4     a visually flashy but narratively opaque and e...\n",
      "...                                                 ...\n",
      "5326  a terrible movie that some people will neverth...\n",
      "5327  there are many definitions of 'time waster' bu...\n",
      "5328  as it stands , crocodile hunter has the hurrie...\n",
      "5329  the thing looks like a made-for-home-video qui...\n",
      "5330  enigma is well-made , but it's just too dry an...\n",
      "\n",
      "[5331 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "with open('negative.txt','r') as file:\n",
    "    lines = file.readlines()\n",
    "neg_df = pd.DataFrame(lines, columns=['Text'])\n",
    "print(neg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "781d0200-dc46-43b3-be77-899ba64055ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df['sentiment'] = 1\n",
    "neg_df['sentiment'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1b01227-d95c-426a-a21c-bd4308891ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effective but too-tepid biopic\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5326</th>\n",
       "      <td>both exuberantly romantic and serenely melanch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5327</th>\n",
       "      <td>mazel tov to a film about a family's joyous li...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5328</th>\n",
       "      <td>standing in the shadows of motown is the best ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5329</th>\n",
       "      <td>it's nice to see piscopo again after all these...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5330</th>\n",
       "      <td>provides a porthole into that noble , tremblin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5331 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  sentiment\n",
       "0     the rock is destined to be the 21st century's ...          1\n",
       "1     the gorgeously elaborate continuation of \" the...          1\n",
       "2                      effective but too-tepid biopic\\n          1\n",
       "3     if you sometimes like to go to the movies to h...          1\n",
       "4     emerges as something rare , an issue movie tha...          1\n",
       "...                                                 ...        ...\n",
       "5326  both exuberantly romantic and serenely melanch...          1\n",
       "5327  mazel tov to a film about a family's joyous li...          1\n",
       "5328  standing in the shadows of motown is the best ...          1\n",
       "5329  it's nice to see piscopo again after all these...          1\n",
       "5330  provides a porthole into that noble , tremblin...          1\n",
       "\n",
       "[5331 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73f23e92-2ca0-43b1-8e57-a93fdf4f8670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (8000, 2)\n",
      "Validation set shape: (1000, 2)\n",
      "Test set shape: (1662, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming pos_df and neg_df are already defined and include a 'sentiment' column\n",
    "\n",
    "# Create the training set\n",
    "train_pos_df = pos_df.iloc[:4000]\n",
    "train_neg_df = neg_df.iloc[:4000]\n",
    "\n",
    "# Create the validation set\n",
    "val_pos_df = pos_df.iloc[4000:4500]\n",
    "val_neg_df = neg_df.iloc[4000:4500]\n",
    "\n",
    "# Create the test set\n",
    "test_pos_df = pos_df.iloc[4500:5331]\n",
    "test_neg_df = neg_df.iloc[4500:5331]\n",
    "\n",
    "# Combine the positive and negative examples for each set\n",
    "train_df = pd.concat([train_pos_df, train_neg_df], ignore_index=True)\n",
    "val_df = pd.concat([val_pos_df, val_neg_df], ignore_index=True)\n",
    "test_df = pd.concat([test_pos_df, test_neg_df], ignore_index=True)\n",
    "\n",
    "# Randomize the rows in each dataset\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "val_df = val_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Display the shapes of the datasets to verify\n",
    "print(\"Training set shape:\", train_df.shape)\n",
    "print(\"Validation set shape:\", val_df.shape)\n",
    "print(\"Test set shape:\", test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8f236e5-7186-4116-b065-4e6a854a420d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>like a veteran head cutter , barbershop is tun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not a bad choice here , assuming that . . . th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it makes you believe the cast and crew thoroug...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'barbershop \" is a good-hearted ensemble comed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>as an entertainment destination for the genera...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>'synthetic' is the best description of this we...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>too intensely focused on the travails of being...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>an elegant , exquisitely modulated psychologic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>it's not helpful to listen to extremist name-c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>as it stands , there's some fine sex onscreen ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  sentiment\n",
       "0     like a veteran head cutter , barbershop is tun...          1\n",
       "1     not a bad choice here , assuming that . . . th...          1\n",
       "2     it makes you believe the cast and crew thoroug...          1\n",
       "3     'barbershop \" is a good-hearted ensemble comed...          1\n",
       "4     as an entertainment destination for the genera...          0\n",
       "...                                                 ...        ...\n",
       "7995  'synthetic' is the best description of this we...          0\n",
       "7996  too intensely focused on the travails of being...          0\n",
       "7997  an elegant , exquisitely modulated psychologic...          1\n",
       "7998  it's not helpful to listen to extremist name-c...          0\n",
       "7999  as it stands , there's some fine sex onscreen ...          0\n",
       "\n",
       "[8000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74fc1165-d28e-473c-8c1f-2834c79249e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text         0\n",
      "sentiment    0\n",
      "dtype: int64\n",
      "Text         0\n",
      "sentiment    0\n",
      "dtype: int64\n",
      "Text         0\n",
      "sentiment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(val_df.isnull().sum())\n",
    "print(train_df.isnull().sum())\n",
    "print(test_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74d76bb5-2b32-48b3-90ff-36acd7bbb8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(val_df.duplicated().sum())\n",
    "print(train_df.duplicated().sum())\n",
    "print(test_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b2a887e-61ff-4fd8-8e48-a8e07b1b9f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub('\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83315413-2481-4db9-b09e-5cd6bd5884b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       like a veteran head cutter barbershop is tuned...\n",
       "1       not a bad choice here assuming that the aircon...\n",
       "2       it makes you believe the cast and crew thoroug...\n",
       "3       barbershop is a goodhearted ensemble comedy wi...\n",
       "4       as an entertainment destination for the genera...\n",
       "                              ...                        \n",
       "7995    synthetic is the best description of this well...\n",
       "7996    too intensely focused on the travails of being...\n",
       "7997    an elegant exquisitely modulated psychological...\n",
       "7998    its not helpful to listen to extremist namecal...\n",
       "7999    as it stands theres some fine sex onscreen and...\n",
       "Name: Text, Length: 8000, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Text'] = train_df['Text'].apply(preprocess_text)\n",
    "train_df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ee708d6-e624-4bf8-a99f-fa9c93004453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      plays like a bad blend of an overripe episode ...\n",
       "1      this movie is about the worst thing chan has d...\n",
       "2      an incredibly irritating comedy about thorough...\n",
       "3      dong never pushes for insights beyond the supe...\n",
       "4      its compelling mix of trial movie escape movie...\n",
       "                             ...                        \n",
       "995    consummate actor barry has done excellent work...\n",
       "996    so beautifully acted and directed its clear th...\n",
       "997    the film was produced by jerry bruckheimer and...\n",
       "998    jones has delivered a solidly entertaining and...\n",
       "999    in questioning the election process payami gra...\n",
       "Name: Text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df['Text'] = val_df['Text'].apply(preprocess_text)\n",
    "val_df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b9fd90c-5b24-4e70-9b20-0b08e46f771b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       when science fiction takes advantage of the fa...\n",
       "1       the hypnotic imagery and fragmentary tale expl...\n",
       "2       even if youve never heard of chaplin youll sti...\n",
       "3       this 90minute dud could pass for mike tysons e...\n",
       "4       a fairly disposable yet still entertaining b p...\n",
       "                              ...                        \n",
       "1657    a film that will probably please people alread...\n",
       "1658    while this one gets off with a good natured wa...\n",
       "1659    mr wollter and ms seldhal give strong and conv...\n",
       "1660    has none of the crackle of fatal attraction 9 ...\n",
       "1661    if you are into splatter movies then you will ...\n",
       "Name: Text, Length: 1662, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Text'] = test_df['Text'].apply(preprocess_text)\n",
    "test_df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faad70ef-bbff-4535-8e02-521cc9bcd5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7dfb0d5-d85f-4b0d-a96f-9dca40dfad4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ambhi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe37ae53-a666-4757-b86a-7af9ca2a1d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to tokenize text\n",
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fd84151-cdc7-4b45-bc0b-e8c4119c14f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [when, science, fiction, takes, advantage, of,...\n",
       "1       [the, hypnotic, imagery, and, fragmentary, tal...\n",
       "2       [even, if, youve, never, heard, of, chaplin, y...\n",
       "3       [this, 90minute, dud, could, pass, for, mike, ...\n",
       "4       [a, fairly, disposable, yet, still, entertaini...\n",
       "                              ...                        \n",
       "1657    [a, film, that, will, probably, please, people...\n",
       "1658    [while, this, one, gets, off, with, a, good, n...\n",
       "1659    [mr, wollter, and, ms, seldhal, give, strong, ...\n",
       "1660    [has, none, of, the, crackle, of, fatal, attra...\n",
       "1661    [if, you, are, into, splatter, movies, then, y...\n",
       "Name: Text, Length: 1662, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_tokens = test_df.copy()\n",
    "test_df_tokens['Text'] = test_df['Text'].apply(tokenize_text)\n",
    "test_df_tokens['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6082f649-8c85-41a5-860b-cb5990192050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [like, a, veteran, head, cutter, barbershop, i...\n",
       "1       [not, a, bad, choice, here, assuming, that, th...\n",
       "2       [it, makes, you, believe, the, cast, and, crew...\n",
       "3       [barbershop, is, a, goodhearted, ensemble, com...\n",
       "4       [as, an, entertainment, destination, for, the,...\n",
       "                              ...                        \n",
       "7995    [synthetic, is, the, best, description, of, th...\n",
       "7996    [too, intensely, focused, on, the, travails, o...\n",
       "7997    [an, elegant, exquisitely, modulated, psycholo...\n",
       "7998    [its, not, helpful, to, listen, to, extremist,...\n",
       "7999    [as, it, stands, theres, some, fine, sex, onsc...\n",
       "Name: Text, Length: 8000, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_tokens = train_df.copy()\n",
    "train_df_tokens['Text'] = train_df['Text'].apply(tokenize_text)\n",
    "train_df_tokens['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b979c7dd-504c-41d8-a892-a6fc2eda8241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [plays, like, a, bad, blend, of, an, overripe,...\n",
       "1      [this, movie, is, about, the, worst, thing, ch...\n",
       "2      [an, incredibly, irritating, comedy, about, th...\n",
       "3      [dong, never, pushes, for, insights, beyond, t...\n",
       "4      [its, compelling, mix, of, trial, movie, escap...\n",
       "                             ...                        \n",
       "995    [consummate, actor, barry, has, done, excellen...\n",
       "996    [so, beautifully, acted, and, directed, its, c...\n",
       "997    [the, film, was, produced, by, jerry, bruckhei...\n",
       "998    [jones, has, delivered, a, solidly, entertaini...\n",
       "999    [in, questioning, the, election, process, paya...\n",
       "Name: Text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df_tokens = val_df.copy()\n",
    "val_df_tokens['Text'] = val_df['Text'].apply(tokenize_text)\n",
    "val_df_tokens['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "461fc099-2d1f-4198-8ed2-5d1b6bb0b133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ambhi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "010e70c4-c01f-45e1-a511-d446b75d131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Example DataFrame\n",
    "# train_df = pd.DataFrame({'Text': [['This', 'is', 'a', 'sample', 'text'], ['Another', 'example', 'text']]})\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    return [word for word in words if word.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "456f011e-ebd1-4b45-b25f-40e5b7314c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Text  sentiment\n",
      "0     [like, veteran, head, cutter, barbershop, tune...          1\n",
      "1     [bad, choice, assuming, airconditioning, theat...          1\n",
      "2     [makes, believe, cast, crew, thoroughly, enjoy...          1\n",
      "3     [barbershop, goodhearted, ensemble, comedy, va...          1\n",
      "4     [entertainment, destination, general, public, ...          0\n",
      "...                                                 ...        ...\n",
      "7995  [synthetic, best, description, wellmeaning, be...          0\n",
      "7996  [intensely, focused, travails, hal, hartley, f...          0\n",
      "7997  [elegant, exquisitely, modulated, psychologica...          1\n",
      "7998  [helpful, listen, extremist, namecalling, rega...          0\n",
      "7999  [stands, theres, fine, sex, onscreen, tense, a...          0\n",
      "\n",
      "[8000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "train_df_tokens_stopwords_removed = train_df_tokens.copy()\n",
    "train_df_tokens_stopwords_removed['Text'] = train_df_tokens_stopwords_removed['Text'].apply(remove_stopwords)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(train_df_tokens_stopwords_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3116078d-5523-4008-a79b-327dac956977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Text  sentiment\n",
      "0     [science, fiction, takes, advantage, fact, int...          0\n",
      "1     [hypnotic, imagery, fragmentary, tale, explore...          1\n",
      "2     [even, youve, never, heard, chaplin, youll, st...          1\n",
      "3     [90minute, dud, could, pass, mike, tysons, e, ...          0\n",
      "4     [fairly, disposable, yet, still, entertaining,...          1\n",
      "...                                                 ...        ...\n",
      "1657  [film, probably, please, people, already, fasc...          0\n",
      "1658  [one, gets, good, natured, warning, future, li...          0\n",
      "1659  [mr, wollter, ms, seldhal, give, strong, convi...          0\n",
      "1660  [none, crackle, fatal, attraction, 9, �, weeks...          0\n",
      "1661  [splatter, movies, probably, reasonably, good,...          0\n",
      "\n",
      "[1662 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test_df_tokens_stopwords_removed = test_df_tokens.copy()\n",
    "test_df_tokens_stopwords_removed['Text'] = test_df_tokens_stopwords_removed['Text'].apply(remove_stopwords)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(test_df_tokens_stopwords_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4057b2ac-f52b-4d11-bddf-c154961e15e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Text  sentiment\n",
      "0    [plays, like, bad, blend, overripe, episode, t...          0\n",
      "1    [movie, worst, thing, chan, done, united, states]          0\n",
      "2    [incredibly, irritating, comedy, thoroughly, v...          0\n",
      "3    [dong, never, pushes, insights, beyond, superf...          0\n",
      "4    [compelling, mix, trial, movie, escape, movie,...          1\n",
      "..                                                 ...        ...\n",
      "995  [consummate, actor, barry, done, excellent, work]          1\n",
      "996  [beautifully, acted, directed, clear, washingt...          1\n",
      "997  [film, produced, jerry, bruckheimer, directed,...          0\n",
      "998  [jones, delivered, solidly, entertaining, movi...          1\n",
      "999  [questioning, election, process, payami, graph...          1\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "val_df_tokens_stopwords_removed = val_df_tokens.copy()\n",
    "val_df_tokens_stopwords_removed['Text'] = val_df_tokens_stopwords_removed['Text'].apply(remove_stopwords)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(val_df_tokens_stopwords_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acc0077d-f83c-4554-9838-3911046828a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenArray = train_df_tokens_stopwords_removed['Text'].apply(len)\n",
    "# lenArray.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11d8d03f-dc63-496d-9d9d-9269d152679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "train_df_tokens_stopwords_removed['text_joined'] = train_df_tokens_stopwords_removed['Text'].apply(' '.join)\n",
    "val_df_tokens_stopwords_removed['text_joined'] = val_df_tokens_stopwords_removed['Text'].apply(' '.join)\n",
    "test_df_tokens_stopwords_removed['text_joined'] = test_df_tokens_stopwords_removed['Text'].apply(' '.join)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=50000)\n",
    "X_train = vectorizer.fit_transform(train_df_tokens_stopwords_removed['text_joined'])\n",
    "X_val = vectorizer.transform(val_df_tokens_stopwords_removed['text_joined'])\n",
    "X_test = vectorizer.transform(test_df_tokens_stopwords_removed['text_joined'])\n",
    "\n",
    "# Get the target variables\n",
    "y_train = train_df_tokens_stopwords_removed['sentiment']\n",
    "y_val = val_df_tokens_stopwords_removed['sentiment']\n",
    "y_test = test_df_tokens_stopwords_removed['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e60d9d42-1091-42a5-82a7-177e8adfc4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8000x17443 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 83821 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "520c7049-72ea-468a-96b4-4746899bfcec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a30f29b9-1192-4e1a-89d2-9e39ee989d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Make predictions\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_test_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0257b60-1464-484d-a65c-ab250bfcfcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Evaluate the model\n",
    "def evaluate_model(y_true, y_pred, set_name):\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Precision, Recall, F1-score\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n--- {set_name} Set Metrics ---\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(f\"\\nPrecision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    # Visualize confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {set_name} Set')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca751f59-f5da-4ab3-8c53-8d85548cf347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Validation Set Metrics ---\n",
      "Confusion Matrix:\n",
      "[[396 104]\n",
      " [132 368]]\n",
      "\n",
      "Precision: 0.7797\n",
      "Recall: 0.7360\n",
      "F1-score: 0.7572\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77       500\n",
      "           1       0.78      0.74      0.76       500\n",
      "\n",
      "    accuracy                           0.76      1000\n",
      "   macro avg       0.76      0.76      0.76      1000\n",
      "weighted avg       0.76      0.76      0.76      1000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test Set Metrics ---\n",
      "Confusion Matrix:\n",
      "[[645 186]\n",
      " [214 617]]\n",
      "\n",
      "Precision: 0.7684\n",
      "Recall: 0.7425\n",
      "F1-score: 0.7552\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76       831\n",
      "           1       0.77      0.74      0.76       831\n",
      "\n",
      "    accuracy                           0.76      1662\n",
      "   macro avg       0.76      0.76      0.76      1662\n",
      "weighted avg       0.76      0.76      0.76      1662\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "evaluate_model(y_val, y_val_pred, \"Validation\")\n",
    "\n",
    "# Evaluate on test set\n",
    "evaluate_model(y_test, y_test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65155747-31ef-4c01-bc84-6e5baf89b652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(random_state=42)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the SVM model\n",
    "from sklearn.svm import SVC\n",
    "svm_model = SVC(kernel='rbf', C=1.0, random_state=42)\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7831ca00-3df7-430e-a62e-a1135b03d8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y_true, set_name):\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n--- {set_name} Set Metrics ---\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    # Visualize confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {set_name} Set')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1d8953-1c66-4f94-b477-fea9a626c9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(svm_model, X_val, y_val, \"Validation\")\n",
    "\n",
    "# Evaluate on test set\n",
    "evaluate_model(svm_model, X_test, y_test, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e09c45b-66bd-48ce-b222-236bd91baa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5a4f6e-3ea2-4789-83ee-dbde9fdec0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "X_train = train_df['Text'].values\n",
    "y_train = train_df['sentiment'].values\n",
    "X_val = val_df['Text'].values\n",
    "y_val = val_df['sentiment'].values\n",
    "X_test = test_df['Text'].values\n",
    "y_test = test_df['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccfc318-d4ac-4f11-acb7-c0906d7d8cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 50000\n",
    "max_len = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f3eb9f-2ccf-44fe-aae4-7febd51caf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_val_pad = pad_sequences(X_val_seq, maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1365031-a0d9-4a20-9867-d2e72384c2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(max_words, 128),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    LSTM(32),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6fa876-3cd9-42c3-b914-56882afb19f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_pad, y_train, batch_size=32, epochs=5, validation_data=(X_val_pad, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = (model.predict(X_test_pad) > 0.5).astype(int)\n",
    "\n",
    "# Print confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Print classification report (includes precision, recall, F1-score)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f7cfe9-b5a9-4726-bfac-a8e6327718b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df_tokens_stopwords_removed['text_joined'].values\n",
    "y_train = train_df['sentiment'].values\n",
    "X_val = val_df_tokens_stopwords_removed['text_joined'].values\n",
    "y_val = val_df['sentiment'].values\n",
    "X_test = test_df_tokens_stopwords_removed['text_joined'].values\n",
    "y_test = test_df['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31b97a7-e636-4998-b661-ed8b13f25d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_val_pad = pad_sequences(X_val_seq, maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c40ddb-9ec7-4a2c-8976-aed5b73d31fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_pad, y_train, batch_size=32, epochs=5, validation_data=(X_val_pad, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = (model.predict(X_test_pad) > 0.5).astype(int)\n",
    "\n",
    "# Print confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Print classification report (includes precision, recall, F1-score)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67d2759b-e84b-440f-b083-27ab68da51f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "import time\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b23c98-3957-45a6-89bb-f70ec4272f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df['Text'].values\n",
    "y_train = train_df['sentiment'].values\n",
    "X_val = val_df['Text'].values\n",
    "y_val = val_df['sentiment'].values\n",
    "X_test = test_df['Text'].values\n",
    "y_test = test_df['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217dd0ab-3c60-4b88-869f-b334cfe0ee62",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3d8189-d925-460e-89be-078f3e716545",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize and encode sequences\n",
    "max_len = 128\n",
    "\n",
    "def encode_sequences(texts):\n",
    "    return tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        max_length=max_len,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e703fa0b-3aa2-424a-a86b-3b1c6e2d9390",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = encode_sequences(X_train)\n",
    "val_encodings = encode_sequences(X_val)\n",
    "test_encodings = encode_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc36dfe-2c2c-4b82-ab8a-aae8eb1875b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(\n",
    "    train_encodings['input_ids'], \n",
    "    train_encodings['attention_mask'], \n",
    "    torch.tensor(y_train)\n",
    ")\n",
    "val_dataset = TensorDataset(\n",
    "    val_encodings['input_ids'], \n",
    "    val_encodings['attention_mask'], \n",
    "    torch.tensor(y_val)\n",
    ")\n",
    "test_dataset = TensorDataset(\n",
    "    test_encodings['input_ids'], \n",
    "    test_encodings['attention_mask'], \n",
    "    torch.tensor(y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1046966c-4377-409b-a37d-305b9e6fe035",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32  # Adjust based on your GPU memory\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fefbb8-e434-4941-bfcc-bf5a676b24c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3116905c-cde6-4e7a-ac3a-f59d1667ed24",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-5\u001b[39m)\n\u001b[1;32m      2\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acd8fbe-279c-4ae0-b890-00bcd4b737d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        loss = criterion(logits, labels)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = correct_predictions.double() / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f} - Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Epoch training time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_correct_predictions = 0\n",
    "    val_total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            loss = criterion(logits, labels)\n",
    "            val_total_loss += loss.item()\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            val_correct_predictions += torch.sum(preds == labels)\n",
    "    \n",
    "    val_accuracy = val_correct_predictions.double() / len(val_dataset)\n",
    "    val_avg_loss = val_total_loss / len(val_loader)\n",
    "    print(f\"Validation - Loss: {val_avg_loss:.4f} - Accuracy: {val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdddd74-3511-411f-b847-bad14d85357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_correct_predictions = 0\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        test_correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "test_accuracy = test_correct_predictions.double() / len(test_dataset)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, all_preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6d36ef-d3d0-495c-a9d5-3f0c7867c8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df_tokens_stopwords_removed['text_joined'].values\n",
    "y_train = train_df['sentiment'].values\n",
    "X_val = val_df_tokens_stopwords_removed['text_joined'].values\n",
    "y_val = val_df['sentiment'].values\n",
    "X_test = test_df_tokens_stopwords_removed['text_joined'].values\n",
    "y_test = test_df['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675e61ff-ca38-4902-a0d5-2a9a49fb1e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize and encode sequences\n",
    "max_len = 128\n",
    "\n",
    "def encode_sequences(texts):\n",
    "    return tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        max_length=max_len,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67f4961-63e0-437f-91a6-886ddfb03e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = encode_sequences(X_train)\n",
    "val_encodings = encode_sequences(X_val)\n",
    "test_encodings = encode_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3c35a7-5051-422e-be4e-c2a8b41bd64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(\n",
    "    train_encodings['input_ids'], \n",
    "    train_encodings['attention_mask'], \n",
    "    torch.tensor(y_train)\n",
    ")\n",
    "val_dataset = TensorDataset(\n",
    "    val_encodings['input_ids'], \n",
    "    val_encodings['attention_mask'], \n",
    "    torch.tensor(y_val)\n",
    ")\n",
    "test_dataset = TensorDataset(\n",
    "    test_encodings['input_ids'], \n",
    "    test_encodings['attention_mask'], \n",
    "    torch.tensor(y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80868a8c-7bd9-4d3e-ac8d-832689865cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32  # Adjust based on your GPU memory\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7939fd92-12e8-471e-ae4f-ae63aa973381",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        loss = criterion(logits, labels)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = correct_predictions.double() / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f} - Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Epoch training time: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_correct_predictions = 0\n",
    "    val_total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            loss = criterion(logits, labels)\n",
    "            val_total_loss += loss.item()\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            val_correct_predictions += torch.sum(preds == labels)\n",
    "    \n",
    "    val_accuracy = val_correct_predictions.double() / len(val_dataset)\n",
    "    val_avg_loss = val_total_loss / len(val_loader)\n",
    "    print(f\"Validation - Loss: {val_avg_loss:.4f} - Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "model.eval()\n",
    "test_correct_predictions = 0\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        test_correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "test_accuracy = test_correct_predictions.double() / len(test_dataset)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, all_preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27360aa1-3c7b-420c-8b4c-f06605fc3126",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-03 15:52:04.150461: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-03 15:52:04.324550: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-03 15:52:04.943759: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81e28866-5da0-4dae-b3c2-9789e30f5c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('siebert/sentiment-roberta-large-english')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('siebert/sentiment-roberta-large-english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13de00ea-c34a-4a2a-a732-acd4c4de13b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "def preprocess_data(texts, labels, max_len=128):\n",
    "    inputs = tokenizer(texts.tolist(), max_length=max_len, padding=True, truncation=True, return_tensors='pt')\n",
    "    labels = torch.tensor(labels.values)\n",
    "    return TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n",
    "\n",
    "# Prepare datasets\n",
    "train_dataset = preprocess_data(train_df['Text'], train_df['sentiment'])\n",
    "val_dataset = preprocess_data(val_df['Text'], val_df['sentiment'])\n",
    "test_dataset = preprocess_data(test_df['Text'], test_df['sentiment'])\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37e76182-2492-4cb1-b454-cf8f1926a342",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenized_texts, labels=None):\n",
    "        self.tokenized_texts = tokenized_texts\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_texts[\"input_ids\"])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.tokenized_texts.items()}\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5487411e-bf73-4579-ad2a-d5d70e878f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Initialize GradScaler\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Set the model to training mode\n",
    "model.train()\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed833fc1-e299-43ee-aec9-d102fa29b4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "# Prune the fully connected layers (or other layers you want to prune)\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Linear):  # You can also target other layer types\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4361db40-04cd-4c65-8054-344b375e73b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Forward pass with autocast\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast():\n\u001b[0;32m---> 19\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Calculate the loss manually if it's not included in the output\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:1198\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1198\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1209\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1210\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:835\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    826\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    828\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    829\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    830\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    833\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    834\u001b[0m )\n\u001b[0;32m--> 835\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    847\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    848\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:524\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    513\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    514\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    515\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    521\u001b[0m         output_attentions,\n\u001b[1;32m    522\u001b[0m     )\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 524\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    534\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:455\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    452\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    453\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 455\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pytorch_utils.py:237\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:467\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 467\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:365\u001b[0m, in \u001b[0;36mRobertaIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 365\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1582\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1580\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1582\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1584\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1585\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1586\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1587\u001b[0m     ):\n\u001b[1;32m   1588\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "for epoch in range(3):  # Replace with the number of epochs you want\n",
    "    for batch in train_loader:\n",
    "        # Unpack the batch into inputs, attention masks, and labels\n",
    "        input_ids, attention_masks, labels = batch\n",
    "\n",
    "        # Move inputs and labels to GPU\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_masks = attention_masks.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Prepare the input dictionary for the model\n",
    "        inputs = {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_masks\n",
    "        }\n",
    "\n",
    "        # Forward pass with autocast\n",
    "        with autocast():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "        \n",
    "        # Calculate the loss manually if it's not included in the output\n",
    "        loss = torch.nn.functional.cross_entropy(logits, labels)\n",
    "\n",
    "        # Backward pass with scaled gradients\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} completed\")\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "12b71dce-d936-4bca-95cf-b7d5feca62a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ambhi/.local/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 23\u001b[0m\n\u001b[1;32m     15\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     16\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,                         \u001b[38;5;66;03m# the instantiated 🤗 Transformers model to be trained\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,                  \u001b[38;5;66;03m# training arguments, defined above\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,         \u001b[38;5;66;03m# training dataset\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mval_dataset             \u001b[38;5;66;03m# evaluation dataset\u001b[39;00m\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:1624\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2017\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2014\u001b[0m         grad_norm \u001b[38;5;241m=\u001b[39m _grad_norm\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m _grad_norm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2016\u001b[0m \u001b[38;5;66;03m# Optimizer step\u001b[39;00m\n\u001b[0;32m-> 2017\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2018\u001b[0m optimizer_was_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39moptimizer_step_was_skipped\n\u001b[1;32m   2019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer_was_run:\n\u001b[1;32m   2020\u001b[0m     \u001b[38;5;66;03m# Delay optimizer scheduling until metrics are generated\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/optimizer.py:149\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 149\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator_state\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mXLA:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_state\u001b[38;5;241m.\u001b[39mis_xla_gradients_synced \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             )\n\u001b[0;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adamw.py:188\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    175\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    177\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    178\u001b[0m         group,\n\u001b[1;32m    179\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    185\u001b[0m         state_steps,\n\u001b[1;32m    186\u001b[0m     )\n\u001b[0;32m--> 188\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adamw.py:340\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 340\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adamw.py:609\u001b[0m, in \u001b[0;36m_multi_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    607\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_foreach_sqrt(device_max_exp_avg_sqs)\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 609\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_sqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_exp_avg_sqs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    611\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_div_(exp_avg_sq_sqrt, bias_correction2_sqrt)\n\u001b[1;32m    612\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_add_(exp_avg_sq_sqrt, eps)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=3,              # number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size for training\n",
    "    per_device_eval_batch_size=32,   # batch size for evaluation\n",
    "    warmup_steps=100,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\"      # Evaluate every epoch\n",
    ")\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset             # evaluation dataset\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69fce222-5cb7-46ce-9684-d1f7938162e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "487"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74bca56a-7d6b-464a-bfb7-11433a3365e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>like a veteran head cutter barbershop is tuned...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not a bad choice here assuming that the aircon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it makes you believe the cast and crew thoroug...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>barbershop is a goodhearted ensemble comedy wi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>as an entertainment destination for the genera...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>synthetic is the best description of this well...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>too intensely focused on the travails of being...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>an elegant exquisitely modulated psychological...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>its not helpful to listen to extremist namecal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>as it stands theres some fine sex onscreen and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  sentiment\n",
       "0     like a veteran head cutter barbershop is tuned...          1\n",
       "1     not a bad choice here assuming that the aircon...          1\n",
       "2     it makes you believe the cast and crew thoroug...          1\n",
       "3     barbershop is a goodhearted ensemble comedy wi...          1\n",
       "4     as an entertainment destination for the genera...          0\n",
       "...                                                 ...        ...\n",
       "7995  synthetic is the best description of this well...          0\n",
       "7996  too intensely focused on the travails of being...          0\n",
       "7997  an elegant exquisitely modulated psychological...          1\n",
       "7998  its not helpful to listen to extremist namecal...          0\n",
       "7999  as it stands theres some fine sex onscreen and...          0\n",
       "\n",
       "[8000 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a597ab-77de-4899-98c7-ebd27d2abc3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
